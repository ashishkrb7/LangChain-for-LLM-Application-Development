
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="LangChain for LLM Application Development">
      
      
        <meta name="author" content="Ashish Kumar">
      
      
      
        <link rel="prev" href="../Model_prompt_parser/">
      
      
        <link rel="next" href="../Chains/">
      
      <link rel="icon" href="../images/favicon.ico">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.12">
    
    
      
        <title>Memory - LangChain for LLM Application Development</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.85bb2934.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.a6bdf11c.min.css">
      
      

    
    
    
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
        html.glightbox-open { overflow: initial; height: 100%; }
        .gslide-title { margin-top: 0px; user-select: text; }
        .gslide-desc { color: #666; user-select: text; }
        .gslide-image img { background: white; }
        
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
            </style> <script src="../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#langchain-memory" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="LangChain for LLM Application Development" class="md-header__button md-logo" aria-label="LangChain for LLM Application Development" data-md-component="logo">
      
  <img src="../images/langchain-logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LangChain for LLM Application Development
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Memory
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href=".." class="md-tabs__link">
      Introduction
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../Model_prompt_parser/" class="md-tabs__link">
      Model,Prompts,Parsers
    </a>
  </li>

      
        
  
  
    
  


  <li class="md-tabs__item">
    <a href="./" class="md-tabs__link md-tabs__link--active">
      Memory
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../Chains/" class="md-tabs__link">
      Chains
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../Question_and_Answer/" class="md-tabs__link">
      QnA
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../Agents/" class="md-tabs__link">
      Agents
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../Evaluation/" class="md-tabs__link">
      Evaluation
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../contact/" class="md-tabs__link">
      Contact
    </a>
  </li>

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="LangChain for LLM Application Development" class="md-nav__button md-logo" aria-label="LangChain for LLM Application Development" data-md-component="logo">
      
  <img src="../images/langchain-logo.png" alt="logo">

    </a>
    LangChain for LLM Application Development
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Introduction
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../Model_prompt_parser/" class="md-nav__link">
        Model,Prompts,Parsers
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Memory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Memory
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#outline" class="md-nav__link">
    Outline
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversationbuffermemory" class="md-nav__link">
    ConversationBufferMemory
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversationbufferwindowmemory" class="md-nav__link">
    ConversationBufferWindowMemory
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversationtokenbuffermemory" class="md-nav__link">
    ConversationTokenBufferMemory
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversationsummarymemory" class="md-nav__link">
    ConversationSummaryMemory
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../Chains/" class="md-nav__link">
        Chains
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../Question_and_Answer/" class="md-nav__link">
        QnA
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../Agents/" class="md-nav__link">
        Agents
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../Evaluation/" class="md-nav__link">
        Evaluation
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../contact/" class="md-nav__link">
        Contact
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#outline" class="md-nav__link">
    Outline
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversationbuffermemory" class="md-nav__link">
    ConversationBufferMemory
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversationbufferwindowmemory" class="md-nav__link">
    ConversationBufferWindowMemory
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversationtokenbuffermemory" class="md-nav__link">
    ConversationTokenBufferMemory
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conversationsummarymemory" class="md-nav__link">
    ConversationSummaryMemory
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="langchain-memory">LangChain: Memory</h1>
<h2 id="outline">Outline</h2>
<ul>
<li>ConversationBufferMemory</li>
<li>ConversationBufferWindowMemory</li>
<li>ConversationTokenBufferMemory</li>
<li>ConversationSummaryMemory</li>
</ul>
<p><a class="glightbox" href="../images/MemoryType.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="../images/MemoryType.png" /></a></p>
<p><a class="glightbox" href="../images/Additional_Memory.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="../images/Additional_Memory.png" /></a></p>
<h2 id="conversationbuffermemory">ConversationBufferMemory</h2>
<div class="highlight"><pre><span></span><code><span class="c1">## Get your OpenAI API</span>
<span class="kn">import</span> <span class="nn">openai</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">AzureChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationChain</span>
<span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferMemory</span>

<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span><span class="p">,</span> <span class="n">find_dotenv</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">load_dotenv</span><span class="p">(</span><span class="n">find_dotenv</span><span class="p">())</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Set OpenAI API key</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_TYPE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;api_type&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_BASE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;api_base&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_VERSION&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;api_version&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">llm</span> <span class="o">=</span> <span class="n">AzureChatOpenAI</span><span class="p">(</span><span class="n">deployment_name</span><span class="o">=</span><span class="s2">&quot;chatgpt-gpt35-turbo&quot;</span><span class="p">,</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-35-turbo&quot;</span><span class="p">,</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">()</span>
<span class="n">conversation</span> <span class="o">=</span> <span class="n">ConversationChain</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> 
    <span class="n">memory</span> <span class="o">=</span> <span class="n">memory</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Hi, my name is Andrew&quot;</span><span class="p">)</span>
</code></pre></div>
<pre><code>Error in on_chain_start callback: 'name'


Prompt after formatting:
[32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:

Human: Hi, my name is Andrew
AI:[0m

[1m&gt; Finished chain.[0m





"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?"
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;What is 1+1?&quot;</span><span class="p">)</span>
</code></pre></div>
<pre><code>Error in on_chain_start callback: 'name'


Prompt after formatting:
[32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:
Human: Hi, my name is Andrew
AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?
Human: What is 1+1?
AI:[0m

[1m&gt; Finished chain.[0m





'The answer to 1+1 is 2.'
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;What is my name?&quot;</span><span class="p">)</span>
</code></pre></div>
<pre><code>Error in on_chain_start callback: 'name'


Prompt after formatting:
[32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:
Human: Hi, my name is Andrew
AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?
Human: What is 1+1?
AI: The answer to 1+1 is 2.
Human: What is my name?
AI:[0m

[1m&gt; Finished chain.[0m





'Your name is Andrew, as you mentioned earlier.'
</code></pre>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">memory</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>
</code></pre></div>
<pre><code>Human: Hi, my name is Andrew
AI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?
Human: What is 1+1?
AI: The answer to 1+1 is 2.
Human: What is my name?
AI: Your name is Andrew, as you mentioned earlier.
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>
</code></pre></div>
<pre><code>{'history': "Human: Hi, my name is Andrew\nAI: Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?\nHuman: What is 1+1?\nAI: The answer to 1+1 is 2.\nHuman: What is my name?\nAI: Your name is Andrew, as you mentioned earlier."}
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferMemory</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Hi&quot;</span><span class="p">},</span> 
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s up&quot;</span><span class="p">})</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">memory</span><span class="o">.</span><span class="n">buffer</span><span class="p">)</span>
</code></pre></div>
<pre><code>Human: Hi
AI: What's up
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>
</code></pre></div>
<pre><code>{'history': "Human: Hi\nAI: What's up"}
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Not much, just hanging&quot;</span><span class="p">},</span> 
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;Cool&quot;</span><span class="p">})</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>
</code></pre></div>
<pre><code>{'history': "Human: Hi\nAI: What's up\nHuman: Not much, just hanging\nAI: Cool"}
</code></pre>
<h2 id="conversationbufferwindowmemory">ConversationBufferWindowMemory</h2>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferWindowMemory</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferWindowMemory</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Hi&quot;</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s up&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Not much, just hanging&quot;</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;Cool&quot;</span><span class="p">})</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>
</code></pre></div>
<pre><code>{'history': 'Human: Not much, just hanging\nAI: Cool'}
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationBufferWindowMemory</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conversation</span> <span class="o">=</span> <span class="n">ConversationChain</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> 
    <span class="n">memory</span> <span class="o">=</span> <span class="n">memory</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;Hi, my name is Andrew&quot;</span><span class="p">)</span>
</code></pre></div>
<pre><code>"Hello Andrew, it's nice to meet you. My name is AI. How can I assist you today?"
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;What is 1+1?&quot;</span><span class="p">)</span>
</code></pre></div>
<pre><code>'The answer to 1+1 is 2.'
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;What is my name?&quot;</span><span class="p">)</span>
</code></pre></div>
<pre><code>"I'm sorry, I don't have access to that information. Could you please tell me your name?"
</code></pre>
<h2 id="conversationtokenbuffermemory">ConversationTokenBufferMemory</h2>
<div class="highlight"><pre><span></span><code><span class="ch">#!pip install tiktoken</span>
</code></pre></div>
<p>Below notebook will be helpfull to understand how to use tiktoken library to generate tokens for your application.</p>
<p>https://github.com/pinecone-io/examples/blob/master/generation/langchain/handbook/03-langchain-conversational-memory.ipynb</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationTokenBufferMemory</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span>
    <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;text-davinci-003&#39;</span>  <span class="c1"># can be used with llms like &#39;gpt-3.5-turbo&#39;</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationTokenBufferMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">max_token_limit</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;AI is what?!&quot;</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;Amazing!&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Backpropagation is what?&quot;</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;Beautiful!&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Chatbots are what?&quot;</span><span class="p">},</span> 
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;Charming!&quot;</span><span class="p">})</span>
<span class="c1"># Ideally you should use ChatGPT, I am getting error ```Warning: model not found. Using cl100k_base encoding.```. So, I am using Instruct GPT.</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>
</code></pre></div>
<pre><code>{'history': 'AI: Amazing!\nHuman: Backpropagation is what?\nAI: Beautiful!\nHuman: Chatbots are what?\nAI: Charming!'}
</code></pre>
<h2 id="conversationsummarymemory">ConversationSummaryMemory</h2>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationSummaryBufferMemory</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># create a long string</span>
<span class="n">schedule</span> <span class="o">=</span> <span class="s2">&quot;There is a meeting at 8am with your product team. </span><span class="se">\</span>
<span class="s2">You will need your powerpoint presentation prepared. </span><span class="se">\</span>
<span class="s2">9am-12pm have time to work on your LangChain </span><span class="se">\</span>
<span class="s2">project which will go quickly because Langchain is such a powerful tool. </span><span class="se">\</span>
<span class="s2">At Noon, lunch at the italian resturant with a customer who is driving </span><span class="se">\</span>
<span class="s2">from over an hour away to meet you to understand the latest in AI. </span><span class="se">\</span>
<span class="s2">Be sure to bring your laptop to show the latest LLM demo.&quot;</span>

<span class="n">memory</span> <span class="o">=</span> <span class="n">ConversationSummaryBufferMemory</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">max_token_limit</span><span class="o">=</span><span class="mi">4000</span><span class="p">)</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Hello&quot;</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;What&#39;s up&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Not much, just hanging&quot;</span><span class="p">},</span>
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="s2">&quot;Cool&quot;</span><span class="p">})</span>
<span class="n">memory</span><span class="o">.</span><span class="n">save_context</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;What is on the schedule today?&quot;</span><span class="p">},</span> 
                    <span class="p">{</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">schedule</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">})</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>
</code></pre></div>
<pre><code>{'history': "Human: Hello\nAI: What's up\nHuman: Not much, just hanging\nAI: Cool\nHuman: What is on the schedule today?\nAI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo."}
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">llm_turbo</span> <span class="o">=</span> <span class="n">AzureChatOpenAI</span><span class="p">(</span><span class="n">deployment_name</span><span class="o">=</span><span class="s2">&quot;chatgpt-gpt35-turbo&quot;</span><span class="p">,</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;gpt-35-turbo&quot;</span><span class="p">,</span><span class="n">temperature</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">conversation</span> <span class="o">=</span> <span class="n">ConversationChain</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm_turbo</span><span class="p">,</span> 
    <span class="n">memory</span> <span class="o">=</span> <span class="n">memory</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">conversation</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="s2">&quot;What would be a good demo to show?&quot;</span><span class="p">)</span>
</code></pre></div>
<pre><code>Error in on_chain_start callback: 'name'


Prompt after formatting:
[32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

Current conversation:
Human: Hello
AI: What's up
Human: Not much, just hanging
AI: Cool
Human: What is on the schedule today?
AI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.
Human: What would be a good demo to show?
AI:[0m

[1m&gt; Finished chain.[0m





"Based on the customer's interests, I would recommend showing the LLM's natural language processing capabilities and how it can be used to analyze large amounts of data quickly and accurately. You could also demonstrate how the LLM can be integrated with other AI tools to create a more comprehensive solution."
</code></pre>
<div class="highlight"><pre><span></span><code><span class="n">memory</span><span class="o">.</span><span class="n">load_memory_variables</span><span class="p">({})</span>
</code></pre></div>
<pre><code>{'history': "Human: Hello\nAI: What's up\nHuman: Not much, just hanging\nAI: Cool\nHuman: What is on the schedule today?\nAI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\nHuman: What would be a good demo to show?\nAI: Based on the customer's interests, I would recommend showing the LLM's natural language processing capabilities and how it can be used to analyze large amounts of data quickly and accurately. You could also demonstrate how the LLM can be integrated with other AI tools to create a more comprehensive solution."}
</code></pre>
<div class="highlight"><pre><span></span><code>
</code></pre></div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 Ashish Kumar
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/ashishkrb7/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections"], "search": "../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.c2be25ad.min.js"></script>
      
    
  <script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body>
</html>